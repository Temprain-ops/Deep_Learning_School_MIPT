{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Копия блокнота \"[homework]TextSummarization.ipynb\"","provenance":[{"file_id":"1KtE4qM8HNhjaSi2_d8tRi550Z26seb99","timestamp":1606501560813}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"widgets":{"application/vnd.jupyter.widget-state+json":{"56996867f05c4c95942780481da7fada":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7a4191525f144d16a91bc7a5d644a657","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b87a24e6c26948959f29c837d4287c53","IPY_MODEL_de84d8d0385a4f1c9c0ecb2bcb485e95"]}},"7a4191525f144d16a91bc7a5d644a657":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b87a24e6c26948959f29c837d4287c53":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_eb7446eae19d409a83956c7cea9dbdf7","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":1000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8bd7160ff5c54bd7994901c3ecf2db34"}},"de84d8d0385a4f1c9c0ecb2bcb485e95":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f689296e34bb4e14bd0fff47ab49584f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1000/1000 [01:17&lt;00:00, 12.98it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1cb3f28aeaad4b23824c8b88635192cb"}},"eb7446eae19d409a83956c7cea9dbdf7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8bd7160ff5c54bd7994901c3ecf2db34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f689296e34bb4e14bd0fff47ab49584f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1cb3f28aeaad4b23824c8b88635192cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"03a8fb832f27411daf9fed69d0fb093a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c37cd97f985d4a69aa6eb9298b484951","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2523f0f5bed14c9e910b7c37553afdd2","IPY_MODEL_ef6fc11b61254ec8958246378a1aa8e2"]}},"c37cd97f985d4a69aa6eb9298b484951":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2523f0f5bed14c9e910b7c37553afdd2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_926b75b0de9a496d8bb319e1493f717a","_dom_classes":[],"description":"Train Loss: 0.188, Valid Loss: 0.177:   0%","_model_name":"FloatProgressModel","bar_style":"","max":8817,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5f56952eb16d44cfac6c9a0cadf3e5f9"}},"ef6fc11b61254ec8958246378a1aa8e2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ea725010188a4af8bf1bc3f2065fe68e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/8817 [00:19&lt;05:53, 24.98it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d1dcbc1b5cc1485eba3a9be54dd07cfb"}},"926b75b0de9a496d8bb319e1493f717a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5f56952eb16d44cfac6c9a0cadf3e5f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ea725010188a4af8bf1bc3f2065fe68e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d1dcbc1b5cc1485eba3a9be54dd07cfb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e99247702d0147dea9f6ba787a8e21da":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_620191ee8a3044abbcec13253b9b5a46","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_07911bac7aa445bfb1f93ce33163580d","IPY_MODEL_f81c5004fd334512a89217d10ead4a4a"]}},"620191ee8a3044abbcec13253b9b5a46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"07911bac7aa445bfb1f93ce33163580d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9eeec326b4d64845b4ab94757a482244","_dom_classes":[],"description":"Epoch: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_53443b4899a34f2aa235b1303d799fd1"}},"f81c5004fd334512a89217d10ead4a4a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_409c9e6b6fe641dca1ca8ad50ea3c5ac","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [08:40&lt;00:00, 520.28s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_54947ef839bd4ceeab558b1c56134df8"}},"9eeec326b4d64845b4ab94757a482244":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"53443b4899a34f2aa235b1303d799fd1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"409c9e6b6fe641dca1ca8ad50ea3c5ac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"54947ef839bd4ceeab558b1c56134df8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"17f359d40900472b901aafa7aa973d80":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bd89cba505454debbdec01ed9e6ac7d2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6b27a7ba27994cfdaee00e97f8839e13","IPY_MODEL_b2aec7f6d424432797e08abf6bef304f"]}},"bd89cba505454debbdec01ed9e6ac7d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6b27a7ba27994cfdaee00e97f8839e13":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_835e1edb31b74142b8e56b105cb350df","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"","max":1443,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1443,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4337904be1da4e198483f1206f725c42"}},"b2aec7f6d424432797e08abf6bef304f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1e7110054ea8452d84962639e9674564","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1443/1443 [01:01&lt;00:00, 24.28it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5dafeebe761f408e8577ee226e37e565"}},"835e1edb31b74142b8e56b105cb350df":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4337904be1da4e198483f1206f725c42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1e7110054ea8452d84962639e9674564":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5dafeebe761f408e8577ee226e37e565":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"Kmb8UhIzOnfK"},"source":["# Text Summarization. Homework\n","\n","Всем привет! Это домашка по суммаризации текста.\n","\n","На семинаре мы рассмотрели базовые модели для суммаризации текста. Попробуйте теперь улучшить два метода: TextRank и Extractive RNN. Задание достаточно большое и требует хорошую фантазию, тут можно эксперементировать во всю.\n","\n","Для сдачи заданий надо получить определенное качество по test-у:\n","\n","- 1 задание: 0.35 BLEU\n","- 2 задание: 0.35 BLEU\n","\n","Если ваш подход пробивает это качество – задание считается пройденным. Плюсом будет описание того, почему вы решили использовать то или иное решение. \n","\n","Датасет: gazeta.ru\n","\n","**P.S.** Возможно, в датасете находятся пустые данные. Проверьте эту гипотезу, и если надо, сделайте предобратоку датасета.\n","\n","\n","`Ноутбук создан на основе семинара Гусева Ильи на кафедре компьютерной лингвистики МФТИ.`\n","\n","Загрузим датасет и необходимые библиотеки"]},{"cell_type":"code","metadata":{"id":"OqkLTkFRfXvA"},"source":["!wget -q https://www.dropbox.com/s/43l702z5a5i2w8j/gazeta_train.txt\n","!wget -q https://www.dropbox.com/s/k2egt3sug0hb185/gazeta_val.txt\n","!wget -q https://www.dropbox.com/s/3gki5n5djs9w0v6/gazeta_test.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SXS1sdYZCluU"},"source":["!pip install -Uq razdel allennlp torch fasttext OpenNMT-py networkx pymorphy2 nltk rouge==0.3.1 summa\n","!pip install -Uq transformers youtokentome\n","!pip install -U ntlk"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5pZ2UGS2DGjH"},"source":["import random\n","import pandas as pd\n","\n","def read_gazeta_records(file_name, shuffle=True, sort_by_date=False):\n","    assert shuffle != sort_by_date\n","    records = []\n","    with open(file_name, \"r\") as r:\n","        for line in r:\n","            if line!=\"\":\n","                records.append(eval(line)) # Simple hack\n","\n","    records = pd.DataFrame(records)\n","    if sort_by_date:\n","        records = records.sort(\"date\")\n","    if shuffle:\n","        records = records.sample(frac=1)\n","    return records"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GNDp-BunEA91"},"source":["train_records = read_gazeta_records(\"gazeta_train.txt\")\n","val_records = read_gazeta_records(\"gazeta_val.txt\")\n","test_records = read_gazeta_records(\"gazeta_test.txt\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cidf8ZCCGFPf"},"source":["import torch\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QsAcVSli3r3S"},"source":["## 1 задание: TextRank (порог: 0.35 BLEU)"]},{"cell_type":"markdown","metadata":{"id":"c7jAQp-_Ds98"},"source":["TextRank - unsupervised метод для составления кратких выжимок из текста. \n","Описание метода:\n","\n","1. Сплитим текст по предложениям\n","2. Считаем \"похожесть\" предложений между собой\n","3. Строим граф предложений с взвешенными ребрами\n","4. С помощью алгоритм PageRank получаем наиболее важные предложения, на основе которых делаем summary.\n","\n","Функция похожести можно сделать и из нейросетевых(или около) моделек: FastText, ELMO и BERT. Выберете один метод, загрузите предобученную модель и с ее помощью для каждого предложениия сделайте sentence embedding. С помощью косинусной меры определяйте похожесть предложений.\n","\n","Предобученные модели можно взять по [ссылке](http://docs.deeppavlov.ai/en/master/features/pretrained_vectors.html)."]},{"cell_type":"code","metadata":{"id":"wjj7PewZGtjm"},"source":["from transformers import AutoTokenizer, AutoModel\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-xCC6L8yqfkU"},"source":["tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased-conversational\")\n","\n","model = AutoModel.from_pretrained(\"DeepPavlov/rubert-base-cased-conversational\")\n","model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sIA40w8TC8FT","executionInfo":{"status":"ok","timestamp":1607273327766,"user_tz":-180,"elapsed":162740,"user":{"displayName":"Илья Волынец","photoUrl":"","userId":"08811045169562879935"}},"outputId":"7b75220b-dd68-4c7b-a1b6-de2ecd0ddc77"},"source":["\n","texts = \"Hi, i want my embedding.\"\n","tokenized=tokenizer.encode(texts, add_special_tokens=True)\n","\n","model.eval()\n","\n","ten=torch.Tensor(tokenized).unsqueeze(0).to(torch.int64).to(device)\n","print(ten)\n","attention_mask = torch.Tensor(np.ones(ten.shape[1])).unsqueeze(0).to(device)\n","print(attention_mask)\n","print(model(ten,attention_mask=attention_mask)[0].shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([[  101, 20577,   128,   248, 22040, 15639, 10778, 78644, 14483,   132,\n","           102]], device='cuda:0')\n","tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], device='cuda:0')\n","torch.Size([1, 11, 768])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WxoV9T2PopQI"},"source":["from nltk.translate.bleu_score import corpus_bleu\n","from rouge import Rouge\n","\n","def calc_scores(references, predictions, metric=\"all\"):\n","    print(\"Count:\", len(predictions))\n","    print(\"Ref:\", references[-1])\n","    print(\"Hyp:\", predictions[-1])\n","\n","    if metric in (\"bleu\", \"all\"):\n","        print(\"BLEU: \", corpus_bleu([[r] for r in references], predictions))\n","    if metric in (\"rouge\", \"all\"):\n","        rouge = Rouge()\n","        scores = rouge.get_scores(predictions, references, avg=True)\n","        print(\"ROUGE: \", scores)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m2GwyRrMPAzS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607273330053,"user_tz":-180,"elapsed":2270,"user":{"displayName":"Илья Волынец","photoUrl":"","userId":"08811045169562879935"}},"outputId":"8603044c-14db-48aa-d4cf-69b8791675ac"},"source":["import nltk\n","nltk.download('stopwords')\n","\n","from itertools import combinations\n","from sklearn.metrics.pairwise import cosine_similarity\n","from nltk.corpus import stopwords\n","\n","\n","import string\n","import networkx as nx\n","import pymorphy2\n","import razdel\n","\n","\n","stopwords=stopwords.words('russian')\n","\n","\n","def clean_string(text):\n","    text=''.join([words for words in text if words not in string.punctuation])\n","    text=text.lower()\n","    text=' '.join([words for words in text.split() if words not in stopwords])\n","    return text\n","\n","\n","def your_super_words_similarity(words1, words2):\n","    # Your code\n","    return cosine_similarity(torch.reshape(words1,(1,words1.shape[0]*words1.shape[1])).cpu().detach(),torch.reshape(words2,(1,words2.shape[0]*words2.shape[1])).cpu().detach())\n","    \n","\n","def gen_text_rank_summary(text, calc_similarity, summary_part=0.1, lower=True, morph=None):\n","    '''\n","    Составление summary с помощью TextRank\n","    '''\n","\n","    \n","    # Разбиваем текст на предложения и отчищаем от пунктуации и местоимений\n","    sentences = [clean_string(sentence.text) for sentence in razdel.sentenize(text)]\n","    n_sentences = len(sentences)\n","    \n","    \n","    tokenized=[tokenizer.encode(sentence) for sentence in sentences]\n","    \n","    max_len = 0\n","    for i in tokenized:\n","        if len(i) > max_len:\n","            max_len = len(i)\n","    \n","    padded = torch.Tensor(np.array([i + [0]*(max_len-len(i)) for i in tokenized])).to(torch.int64)\n","    attention_mask = torch.Tensor(np.where(padded != 0, 1, 0)).to(device)\n","    padded=padded.to(device)\n","\n","    embedded=model(padded,attention_mask=attention_mask)[0]\n","    # Для каждой пары предложений считаем близость\n","    pairs = combinations(range(n_sentences), 2)\n","    scores = [(i, j, calc_similarity(embedded[i], embedded[j])) for i, j in pairs]\n","    \n","    # Строим граф с рёбрами, равными близости между предложениями\n","    g = nx.Graph()\n","    g.add_weighted_edges_from(scores)\n","\n","    # Считаем PageRank\n","    pr = nx.pagerank(g)\n","    result = [(i, pr[i], s) for i, s in enumerate(sentences) if i in pr]\n","    result.sort(key=lambda x: x[1], reverse=True)\n","\n","    # Выбираем топ предложений\n","    n_summary_sentences = max(int(n_sentences * summary_part), 1)\n","    result = result[:n_summary_sentences]\n","\n","    # Восстанавливаем оригинальный их порядок\n","    result.sort(key=lambda x: x[0])\n","\n","    # Восстанавливаем текст выжимки\n","    predicted_summary = \" \".join([sentence for i, proba, sentence in result])\n","    predicted_summary = predicted_summary.lower() if lower else predicted_summary\n","    return predicted_summary\n","\n","def calc_text_rank_score(records, calc_similarity, summary_part=0.1, lower=True, nrows=1000, morph=None):\n","    references = []\n","    predictions = []\n","\n","    for text, summary in records[['text', 'summary']].values[:nrows]:\n","        summary = summary if not lower else summary.lower()\n","        references.append(summary)\n","\n","        predicted_summary = gen_text_rank_summary(text, calc_similarity, summary_part, lower, morph=morph)\n","        text = text if not lower else text.lower()\n","        predictions.append(predicted_summary)\n","\n","    calc_scores(references, predictions)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"cNYGTGRFopQJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607268586088,"user_tz":-180,"elapsed":878017,"user":{"displayName":"Илья Волынец","photoUrl":"","userId":"08811045169562879935"}},"outputId":"b3c18188-d5a9-4cf8-8c67-217d75d074b2"},"source":["calc_text_rank_score(test_records, calc_similarity=your_super_words_similarity)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Count: 1000\n","Ref: президент россии владимир путин назначил нового посла россии в великобритании. им стал специалист по европейским делам александр келин, который имеет 40-летний опыт работы на дипломатической службе. в москву вскоре также прибудет визави келина, так как посол великобритании в россии лори бристоу также покидает свой пост. москва и лондон при этом все еще находятся в несколько конфронтационных отношениях из-за «дела скрипаля».\n","Hyp: келин начал дипломатическую карьеру 1979 году качестве сотрудника посольства ссср нидерландах назначения послом келин занимал пост главы департамента общеевропейского сотрудничества мид россии сообщил посол бристоу джонсон примет решение позже\n","BLEU:  0.3679220843028809\n","ROUGE:  {'rouge-1': {'f': 0.10783962585225354, 'p': 0.11855957284495604, 'r': 0.10506694022156235}, 'rouge-2': {'f': 0.024314317341197395, 'p': 0.02653454264652973, 'r': 0.023953523981536183}, 'rouge-l': {'f': 0.08941328829434171, 'p': 0.10393538594839234, 'r': 0.09183002488235227}}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xdTrfxycB7cd"},"source":["## 2 Задание: Extractive RNN (порог: 0.35 BLEU)"]},{"cell_type":"markdown","metadata":{"id":"6Q7DeHDYFSjX"},"source":["Второй метод, который вам предлагается улучшить – поиск предложений для summary с помощью RNN. В рассмотренной методе мы использовали LSTM для генерации sentence embedding. Попробуйте использовать другие архитектуры: CNN, Transformer; или добавьте предобученные модели, как и в первом задании.\n","\n","P.S. Тут предполагается, что придется изменять много кода в ячееках (например, поменять токенизацию). "]},{"cell_type":"markdown","metadata":{"id":"1dZamxigdEc-"},"source":["### Модель\n","\n","Картинка для привлечения внимания:\n","\n","![img](https://storage.googleapis.com/groundai-web-prod/media%2Fusers%2Fuser_14%2Fproject_398421%2Fimages%2Farchitecture.png)\n","\n","Статья с оригинальным методом:\n","https://arxiv.org/pdf/1611.04230.pdf\n","\n","Список вдохновения: \n","- https://towardsdatascience.com/understanding-how-convolutional-neural-network-cnn-perform-text-classification-with-word-d2ee64b9dd0b Пример того, как можно применять CNN в текстовых задачах\n","- https://arxiv.org/pdf/1808.08745.pdf Очень крутой метод генерации summary без Transformers\n","- https://towardsdatascience.com/super-easy-way-to-get-sentence-embedding-using-fasttext-in-python-a70f34ac5b7c – простой метод генерации sentence embedding\n","- https://towardsdatascience.com/fse-2b1ffa791cf9 – Необычный метод генерации sentence embedding\n","- https://github.com/UKPLab/sentence-transformers – BERT предобученный для sentence embedding\n","\n","P.S. Выше написанные ссылки нужны только для разогрева вашей фантазии, можно воспользоваться ими, а можно придумать свой."]},{"cell_type":"markdown","metadata":{"id":"lOH4ZbLkg_sM"},"source":["Комментарий к заданию:\n","Если посмотреть на архитектуру ~~почти~~ SummaRuNNer, то в ней есть два главных элемента: первая часть, которая читает предложения и возвращает векторы на каждое предложение, и вторая, которая выбирает предложения для суммаризации. Вторую часть мы не трогаем, а первую меняем. На что меняем – как вы решите. Главное: она должна иметь хорошее качество и встроиться в текущую модель."]},{"cell_type":"code","metadata":{"id":"Sxsc0Orf8hGq"},"source":["import copy\n","import random\n","\n","def build_oracle_summary_greedy(text, gold_summary, calc_score, lower=True, max_sentences=30):\n","    '''\n","    Жадное построение oracle summary\n","    '''\n","    gold_summary = gold_summary.lower() if lower else gold_summary\n","    # Делим текст на предложения\n","    sentences = [sentence.text.lower() if lower else sentence.text for sentence in razdel.sentenize(text)][:max_sentences]\n","    n_sentences = len(sentences)\n","    oracle_summary_sentences = set()\n","    score = -1.0\n","    summaries = []\n","    for _ in range(min(n_sentences, 2)):\n","        for i in range(n_sentences):\n","            if i in oracle_summary_sentences:\n","                continue\n","            current_summary_sentences = copy.copy(oracle_summary_sentences)\n","            # Добавляем какое-то предложения к уже существующему summary\n","            current_summary_sentences.add(i)\n","            current_summary = \" \".join([sentences[index] for index in sorted(list(current_summary_sentences))])\n","            # Считаем метрики\n","            current_score = calc_score(current_summary, gold_summary)\n","            summaries.append((current_score, current_summary_sentences))\n","        # Если получилось улучшить метрики с добавлением какого-либо предложения, то пробуем добавить ещё\n","        # Иначе на этом заканчиваем\n","        best_summary_score, best_summary_sentences = max(summaries)\n","        if best_summary_score <= score:\n","            break\n","        oracle_summary_sentences = best_summary_sentences\n","        score = best_summary_score\n","    oracle_summary = \" \".join([sentences[index] for index in sorted(list(oracle_summary_sentences))])\n","    return oracle_summary, oracle_summary_sentences\n","\n","def calc_single_score(pred_summary, gold_summary, rouge):\n","    return rouge.get_scores([pred_summary], [gold_summary], avg=True)['rouge-2']['f']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7T_ak-KDB8rp","colab":{"base_uri":"https://localhost:8080/","height":220,"referenced_widgets":["56996867f05c4c95942780481da7fada","7a4191525f144d16a91bc7a5d644a657","b87a24e6c26948959f29c837d4287c53","de84d8d0385a4f1c9c0ecb2bcb485e95","eb7446eae19d409a83956c7cea9dbdf7","8bd7160ff5c54bd7994901c3ecf2db34","f689296e34bb4e14bd0fff47ab49584f","1cb3f28aeaad4b23824c8b88635192cb"]},"executionInfo":{"status":"ok","timestamp":1607268703483,"user_tz":-180,"elapsed":81058,"user":{"displayName":"Илья Волынец","photoUrl":"","userId":"08811045169562879935"}},"outputId":"10ec9884-3783-4010-cf62-209bc874d145"},"source":["from tqdm import tqdm_notebook as tqdm\n","\n","def calc_oracle_score(records, nrows=1000, lower=True):\n","    references = []\n","    predictions = []\n","    rouge = Rouge()\n","  \n","    for text, summary in tqdm(records[['text', 'summary']].values[:nrows]):\n","        summary = summary if not lower else summary.lower()\n","        references.append(summary)\n","        predicted_summary, _ = build_oracle_summary_greedy(text, summary, calc_score=lambda x, y: calc_single_score(x, y, rouge))\n","        predictions.append(predicted_summary)\n","\n","    calc_scores(references, predictions)\n","\n","calc_oracle_score(test_records)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  \n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"56996867f05c4c95942780481da7fada","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Count: 1000\n","Ref: президент россии владимир путин назначил нового посла россии в великобритании. им стал специалист по европейским делам александр келин, который имеет 40-летний опыт работы на дипломатической службе. в москву вскоре также прибудет визави келина, так как посол великобритании в россии лори бристоу также покидает свой пост. москва и лондон при этом все еще находятся в несколько конфронтационных отношениях из-за «дела скрипаля».\n","Hyp: пост посла россии в лондоне стал вакантным после отъезда занимавшего должность до лета этого года александра яковенко. стоит отметить, что после нового года будет объявлено и о назначении нового посла великобритании в россии, так как эту должность покидает лори бристоу.\n","BLEU:  0.4271604099078064\n","ROUGE:  {'rouge-1': {'f': 0.3548525560527689, 'p': 0.43471814644611295, 'r': 0.3179142321351281}, 'rouge-2': {'f': 0.20455759953866798, 'p': 0.2573780108295503, 'r': 0.1818419402499293}, 'rouge-l': {'f': 0.3042105501645308, 'p': 0.40453597860501955, 'r': 0.2944622780173175}}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uWgjewfWrbJZ"},"source":["## (!)\n","Если надо, поменяйте код загрузки токенизатора"]},{"cell_type":"code","metadata":{"id":"-qIRKm4TCHzN"},"source":["import os\n","\n","import youtokentome as yttm\n","\n","def train_bpe(records, model_path, model_type=\"bpe\", vocab_size=30000, lower=True):\n","    temp_file_name = \"temp.txt\"\n","    with open(temp_file_name, \"w\") as temp:\n","        for text, summary in records[['text', 'summary']].values:\n","            if lower:\n","                summary = summary.lower()\n","                text = text.lower()\n","            if not text or not summary:\n","                continue\n","            temp.write(text + \"\\n\")\n","            temp.write(summary + \"\\n\")\n","    yttm.BPE.train(data=temp_file_name, vocab_size=vocab_size, model=model_path)\n","\n","train_bpe(train_records, \"BPE_model.bin\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xAkZ2f5LhWwE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607273349601,"user_tz":-180,"elapsed":21803,"user":{"displayName":"Илья Волынец","photoUrl":"","userId":"08811045169562879935"}},"outputId":"26685594-afc8-469a-9ef3-a80d9ccce412"},"source":["bpe_processor = yttm.BPE('BPE_model.bin')\n","bpe_processor.encode([\"октябрь богат на изменения\"], output_type=yttm.OutputType.SUBWORD)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['▁октябрь', '▁богат', '▁на', '▁изменения']]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"AOkUL_YIGp-S"},"source":["## (!)\n","Если надо, поменяйте код словаря"]},{"cell_type":"code","metadata":{"id":"GhQYN1beiVEC"},"source":["from collections import Counter\n","from typing import List, Tuple\n","import os\n","\n","class Vocabulary:\n","    def __init__(self, bpe_processor):\n","        self.index2word = bpe_processor.vocab()\n","        self.word2index = {w: i for i, w in enumerate(self.index2word)}\n","        self.word2count = Counter()\n","\n","    def get_pad(self):\n","        return self.word2index[\"<PAD>\"]\n","\n","    def get_sos(self):\n","        return self.word2index[\"<SOS>\"]\n","\n","    def get_eos(self):\n","        return self.word2index[\"<EOS>\"]\n","\n","    def get_unk(self):\n","        return self.word2index[\"<UNK>\"]\n","    \n","    def has_word(self, word) -> bool:\n","        return word in self.word2index\n","\n","    def get_index(self, word):\n","        if word in self.word2index:\n","            return self.word2index[word]\n","        return self.get_unk()\n","\n","    def get_word(self, index):\n","        return self.index2word[index]\n","\n","    def size(self):\n","        return len(self.index2word)\n","\n","    def is_empty(self):\n","        empty_size = 4\n","        return self.size() <= empty_size\n","\n","    def reset(self):\n","        self.word2count = Counter()\n","        self.index2word = [\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"]\n","        self.word2index = {word: index for index, word in enumerate(self.index2word)}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2qvZtNcOifAn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607273349603,"user_tz":-180,"elapsed":21793,"user":{"displayName":"Илья Волынец","photoUrl":"","userId":"08811045169562879935"}},"outputId":"771e084a-c36e-4451-d180-4ba9b9552252"},"source":["vocabulary = Vocabulary(bpe_processor)\n","vocabulary.size()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["30000"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"Jdb-39jO-72q"},"source":["from rouge import Rouge\n","import razdel\n","\n","def add_oracle_summary_to_records(records, max_sentences=30, lower=True, nrows=1000):\n","    rouge = Rouge()\n","    sentences_ = []\n","    oracle_sentences_ = []\n","    oracle_summary_ = []\n","    if nrows is not None:\n","        records = records.iloc[:nrows].copy()\n","    else:\n","        records = records.copy()\n","\n","    for text, summary in tqdm(records[['text', 'summary']].values):\n","        summary = summary.lower() if lower else summary\n","        sentences = [sentence.text.lower() if lower else sentence.text for sentence in razdel.sentenize(text)][:max_sentences]\n","        oracle_summary, sentences_indicies = build_oracle_summary_greedy(text, summary, calc_score=lambda x, y: calc_single_score(x, y, rouge),\n","                                                                         lower=lower, max_sentences=max_sentences)\n","        sentences_ += [sentences]\n","        oracle_sentences_ += [list(sentences_indicies)]\n","        oracle_summary_ += [oracle_summary]\n","    records['sentences'] = sentences_\n","    records['oracle_sentences'] = oracle_sentences_\n","    records['oracle_summary'] = oracle_summary_\n","    return records\n","\n","#ext_train_records = add_oracle_summary_to_records(train_records, nrows=30000)\n","#ext_val_records = add_oracle_summary_to_records(val_records, nrows=None)\n","#ext_test_records = add_oracle_summary_to_records(test_records, nrows=None)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2cD-Cif9opQJ"},"source":["Используй `pickle` для сохранения записей, чтобы потом не пересоздавать их потом. Если решаешь задание в колабе, можешь подключить свой гугл диск и сохранить данные в нём."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vgLXYGmTnpND","executionInfo":{"status":"ok","timestamp":1607273431266,"user_tz":-180,"elapsed":103445,"user":{"displayName":"Илья Волынец","photoUrl":"","userId":"08811045169562879935"}},"outputId":"18235d54-e74e-4627-a4ba-b5b8c34f860e"},"source":["import pickle\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"s6mCV-4DopQJ"},"source":["#file1= open(\"/content/drive/MyDrive/DLS2sem/Summarization/train_records.bin\", 'wb')\n","#pickle.dump(ext_train_records,file1)\n","#file2=open(\"/content/drive/MyDrive/DLS2sem/Summarization/val_records.bin\", 'wb')\n","#pickle.dump(ext_val_records,file2)\n","#file3=open(\"/content/drive/MyDrive/DLS2sem/Summarization/test_records.bin\", 'wb')\n","#pickle.dump(ext_test_records,file3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pB6tPvws2WoY"},"source":["file1= open(\"/content/drive/MyDrive/DLS2sem/Summarization/train_records.bin\", 'rb')\n","ext_train_records=pickle.load(file1)\n","file2= open(\"/content/drive/MyDrive/DLS2sem/Summarization/val_records.bin\", 'rb')\n","ext_val_records=pickle.load(file2)\n","file3= open(\"/content/drive/MyDrive/DLS2sem/Summarization/test_records.bin\", 'rb')\n","ext_test_records=pickle.load(file3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UlXXc8qUHC5m"},"source":["## (!)\n","Если надо, поменяйте код генератора датасета и батчевалки"]},{"cell_type":"code","metadata":{"id":"MNyxstTChK3C"},"source":["import random\n","import math\n","import razdel\n","import torch\n","import numpy as np\n","from rouge import Rouge\n","\n","\n","from torch.utils import data\n","\n","\n","class ExtDataset(data.Dataset):\n","    def __init__(self, records, vocabulary, bpe_processor, lower=True, max_sentences=30, max_sentence_length=50, device=torch.device('cpu')):\n","        self.records = records\n","        self.num_samples = records.shape[0]\n","        self.bpe_processor = bpe_processor\n","        self.lower = lower\n","        self.rouge = Rouge()\n","        self.vocabulary = vocabulary\n","        self.max_sentences = max_sentences\n","        self.max_sentence_length = max_sentence_length\n","        self.device = device\n","        \n","    def __len__(self):\n","        return self.records.shape[0]\n","\n","    def __getitem__(self, idx):\n","        cur_record = self.records.iloc[idx]\n","        inputs = list(map(lambda x: x[:self.max_sentence_length], self.bpe_processor.encode(cur_record['sentences'], output_type=yttm.OutputType.ID)))\n","        outputs = [int(i in cur_record['oracle_sentences']) for i in range(len(cur_record['sentences']))]\n","        return {'inputs': inputs, 'outputs': outputs}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bvARjudojEDD"},"source":["# Это батчевалка\n","def collate_fn(records):\n","    max_length = max(len(sentence) for record in records for sentence in record['inputs'])\n","    max_sentences = max(len(record['outputs']) for record in records)\n","\n","    new_inputs = torch.zeros((len(records), max_sentences, max_length))\n","    new_outputs = torch.zeros((len(records), max_sentences))\n","    for i, record in enumerate(records):\n","        for j, sentence in enumerate(record['inputs']):\n","            new_inputs[i, j, :len(sentence)] += np.array(sentence)\n","        new_outputs[i, :len(record['outputs'])] += np.array(record['outputs'])\n","    return {'features': new_inputs.type(torch.LongTensor), 'targets': new_outputs}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EVe8qoo15iak"},"source":["my_model = AutoModel.from_pretrained(\"DeepPavlov/rubert-base-cased\")\n","my_tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")\n","my_model.to(device)\n","my_model.eval()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aWlf7XdheJUN"},"source":["import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from torch.nn.utils.rnn import pack_padded_sequence as pack\n","from torch.nn.utils.rnn import pad_packed_sequence as unpack\n","\n","\n","class YourSentenceEncoder(nn.Module):\n","    # Место для вашего Sentence Encoder-а. Разрешается использовать любые методы, которые вам нравятся.\n","    def __init__(self, input_size, embedding_dim, hidden_size, n_layers=3, dropout=0.3, bidirectional=True):\n","        super().__init__()\n","        #self.hidden_size=hidden\n","        #self.my_model=my_model\n","        num_directions = 2 if bidirectional else 1\n","        hidden_size = hidden_size // num_directions\n","\n","        self.bidirectional = bidirectional\n","        self.embedding_layer = nn.Embedding(input_size, embedding_dim)\n","        self.rnn_layer = nn.LSTM(embedding_dim, hidden_size, n_layers, dropout=dropout, bidirectional=bidirectional, batch_first=True)\n","        self.dropout_layer = nn.Dropout(dropout)\n","        self.embedding_dim = embedding_dim\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.n_layers = n_layers\n","        self.dropout = dropout\n","       \n","\n","    def forward(self, inputs, hidden=None):\n","        #embedded=self.my_model(inputs)[0]\n","        #sentences_embeddings = torch.mean(embedded, 1)\n","        embedded = self.embedding_layer(inputs)\n","        outputs, _ = self.rnn_layer(embedded, hidden)\n","        sentences_embeddings = torch.mean(outputs, 1)\n","        return sentences_embeddings\n","\n","class SentenceTaggerRNN(nn.Module):\n","    def __init__(self,\n","                 vocabulary_size,\n","                 token_embedding_dim=256,\n","                 sentence_encoder_hidden_size=256,\n","                 hidden_size=256,\n","                 bidirectional=True,\n","                 sentence_encoder_n_layers=2,\n","                 sentence_encoder_dropout=0.3,\n","                 sentence_encoder_bidirectional=True,\n","                 n_layers=3,\n","                 dropout=0.3):\n","        super(SentenceTaggerRNN, self).__init__()\n","\n","        num_directions = 2 if bidirectional else 1\n","        assert hidden_size % num_directions == 0\n","        hidden_size = hidden_size // num_directions\n","\n","        self.hidden_size = hidden_size\n","        self.n_layers = n_layers\n","        self.dropout = dropout\n","        self.bidirectional = bidirectional\n","\n","        # Your sentence encoder model\n","        self.sentence_encoder = YourSentenceEncoder(vocabulary_size, token_embedding_dim,\n","                                                   sentence_encoder_hidden_size, sentence_encoder_n_layers, \n","                                                   sentence_encoder_dropout, sentence_encoder_bidirectional)\n","        \n","        self.rnn_layer = nn.LSTM(\n","            sentence_encoder_hidden_size, \n","            hidden_size, \n","            n_layers, \n","            dropout=dropout,\n","            bidirectional=bidirectional, \n","            batch_first=True)\n","        self.dropout_layer = nn.Dropout(dropout)\n","        self.content_linear_layer = nn.Linear(hidden_size * 2, 1)\n","        self.document_linear_layer = nn.Linear(hidden_size * 2, hidden_size * 2)\n","        self.salience_linear_layer = nn.Linear(hidden_size * 2, hidden_size * 2)\n","        self.tanh_layer = nn.Tanh()\n","\n","    def forward(self, inputs, hidden=None):\n","        \n","        batch_size = inputs.size(0)\n","        sentences_count = inputs.size(1)\n","        \n","        tokens_count = inputs.size(2)\n","        inputs = inputs.reshape(-1, tokens_count)\n","        embedded_sentences = self.sentence_encoder(inputs)\n","        embedded_sentences = embedded_sentences.reshape(batch_size, sentences_count, -1)\n","        outputs, _ = self.rnn_layer(embedded_sentences, hidden)\n","        outputs = self.dropout_layer(outputs)\n","        document_embedding = self.tanh_layer(self.document_linear_layer(torch.mean(outputs, 1)))\n","        content = self.content_linear_layer(outputs).squeeze(2)\n","        salience = torch.bmm(outputs, self.salience_linear_layer(document_embedding).unsqueeze(2)).squeeze(2)\n","        return content + salience\n","\n","model = SentenceTaggerRNN(vocabulary.size())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4q2Gb6ODHHB_"},"source":["### Обучение"]},{"cell_type":"code","metadata":{"id":"UVDW8raJeQxn"},"source":["device = torch.device('cuda')\n","\n","loaders = {\n","    'train': data.DataLoader(\n","        ExtDataset(\n","            ext_train_records, \n","            vocabulary, \n","            bpe_processor=bpe_processor\n","        ), \n","        batch_size=4, \n","        collate_fn=collate_fn\n","    ),\n","    'valid': data.DataLoader(\n","        ExtDataset(\n","            ext_val_records, \n","            vocabulary, \n","            bpe_processor=bpe_processor\n","        ), \n","        batch_size=4, \n","        collate_fn=collate_fn\n","    ),\n","    'test': data.DataLoader(\n","        ExtDataset(\n","            ext_test_records, \n","            vocabulary, \n","            bpe_processor=bpe_processor\n","        ), \n","        batch_size=4, \n","        collate_fn=collate_fn\n","    ),\n","}\n","\n","lr = 1e-4\n","num_epochs = 1\n","\n","optimizer  = torch.optim.AdamW(model.parameters(), lr=lr)\n","criterion = nn.BCEWithLogitsLoss()\n","# Maybe adding scheduler?"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gxyTLjw9opQJ"},"source":["from tqdm.notebook import trange, tqdm\n","\n","\n","def train():\n","    model.to(device)\n","    pbar_loader = trange(len(loaders[\"train\"]) + len(loaders[\"valid\"]), desc=f\"Train Loss: {0}, Valid Loss: {0}\")\n","    for e in trange(num_epochs, desc=\"Epoch\"):\n","        train_loss = 0\n","        valid_loss = 0\n","        train_it = 0\n","        valid_it = 0\n","        \n","        model.train()\n","        for batch in loaders[\"train\"]:\n","            features = batch[\"features\"].to(device)\n","            targets = batch[\"targets\"].to(device)\n","            \n","            logits = model(features)\n","            \n","            loss = criterion(logits, targets)\n","            train_loss += loss.item()\n","            train_it += 1\n","            \n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            # Maybe adding scheduler?\n","            \n","            pbar_loader.update()\n","            pbar_loader.set_description(\n","                f\"Train Loss: {train_loss / train_it:.3}, Valid Loss: {0}\"\n","            )\n","            \n","        model.eval()\n","        with torch.no_grad():\n","            for batch in loaders[\"valid\"]:\n","                features = batch[\"features\"].to(device)\n","                targets = batch[\"targets\"].to(device)\n","\n","                logits = model(features)\n","\n","                loss = criterion(logits, targets)\n","                valid_loss += loss.item()\n","                valid_it += 1\n","                \n","                pbar_loader.update()\n","                pbar_loader.set_description(\n","                    f\"Train Loss: {train_loss / train_it:.3},\"\n","                    f\" Valid Loss: {valid_loss / valid_it:.3}\"\n","                )\n","        print(\n","            f\"Epoch {e}; Train Loss: {train_loss / train_it:.3},\"\n","            f\" Valid Loss: {valid_loss / valid_it:.3}\"\n","        )\n","        pbar_loader.reset()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ywrvtlnfopQJ","colab":{"base_uri":"https://localhost:8080/","height":114,"referenced_widgets":["03a8fb832f27411daf9fed69d0fb093a","c37cd97f985d4a69aa6eb9298b484951","2523f0f5bed14c9e910b7c37553afdd2","ef6fc11b61254ec8958246378a1aa8e2","926b75b0de9a496d8bb319e1493f717a","5f56952eb16d44cfac6c9a0cadf3e5f9","ea725010188a4af8bf1bc3f2065fe68e","d1dcbc1b5cc1485eba3a9be54dd07cfb","e99247702d0147dea9f6ba787a8e21da","620191ee8a3044abbcec13253b9b5a46","07911bac7aa445bfb1f93ce33163580d","f81c5004fd334512a89217d10ead4a4a","9eeec326b4d64845b4ab94757a482244","53443b4899a34f2aa235b1303d799fd1","409c9e6b6fe641dca1ca8ad50ea3c5ac","54947ef839bd4ceeab558b1c56134df8"]},"executionInfo":{"status":"ok","timestamp":1607274048425,"user_tz":-180,"elapsed":521299,"user":{"displayName":"Илья Волынец","photoUrl":"","userId":"08811045169562879935"}},"outputId":"5f9b2913-6189-4bf3-b6c5-288efe38f30a"},"source":["train()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"03a8fb832f27411daf9fed69d0fb093a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Train Loss: 0, Valid Loss: 0', max=8817.0, style=Progress…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e99247702d0147dea9f6ba787a8e21da","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Epoch 0; Train Loss: 0.188, Valid Loss: 0.177\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EwqhK2dyKuGL","colab":{"base_uri":"https://localhost:8080/","height":121,"referenced_widgets":["17f359d40900472b901aafa7aa973d80","bd89cba505454debbdec01ed9e6ac7d2","6b27a7ba27994cfdaee00e97f8839e13","b2aec7f6d424432797e08abf6bef304f","835e1edb31b74142b8e56b105cb350df","4337904be1da4e198483f1206f725c42","1e7110054ea8452d84962639e9674564","5dafeebe761f408e8577ee226e37e565"]},"executionInfo":{"status":"ok","timestamp":1607274134892,"user_tz":-180,"elapsed":83536,"user":{"displayName":"Илья Волынец","photoUrl":"","userId":"08811045169562879935"}},"outputId":"7e89ef7c-e2c4-4510-e5b1-8a6e84bc9dbc"},"source":["device = torch.device(\"cuda\")\n","\n","top_k = 3\n","references = []\n","predictions = []\n","\n","def postprocess(ref, hyp, is_multiple_ref=False, detokenize_after=False, tokenize_after=True):\n","    if is_multiple_ref:\n","        reference_sents = ref.split(\" s_s \")\n","        decoded_sents = hyp.split(\"s_s\")\n","        hyp = [w.replace(\"<\", \"&lt;\").replace(\">\", \"&gt;\").strip() for w in decoded_sents]\n","        ref = [w.replace(\"<\", \"&lt;\").replace(\">\", \"&gt;\").strip() for w in reference_sents]\n","        hyp = \" \".join(hyp)\n","        ref = \" \".join(ref)\n","    ref = ref.strip()\n","    hyp = hyp.strip()\n","    if detokenize_after:\n","        hyp = punct_detokenize(hyp)\n","        ref = punct_detokenize(ref)\n","    if tokenize_after:\n","        hyp = hyp.replace(\"@@UNKNOWN@@\", \"<unk>\")\n","        hyp = \" \".join([token.text for token in razdel.tokenize(hyp)])\n","        ref = \" \".join([token.text for token in razdel.tokenize(ref)])\n","    return ref, hyp\n","\n","model.eval()\n","for num, batch in tqdm(enumerate(loaders[\"test\"]), total = len(loaders[\"test\"]),leave=False):\n","\n","    logits = model(batch[\"features\"].to(device))\n","    in_summary = torch.argsort(logits, dim=1)[:, -top_k:]\n","    for i in range(len(batch['targets'])):\n","\n","        summary = ext_test_records.iloc[i]['summary']\n","        summary = summary.lower()\n","        predicted_summary = ' '.join([ext_test_records.iloc[i]['sentences'][idx] for idx in in_summary[i].sort()[0] if idx < len(ext_test_records.iloc[i]['sentences'])])\n","        summary, predicted_summary = postprocess(summary, predicted_summary)\n","\n","        references.append(summary)\n","        predictions.append(predicted_summary)\n","\n","calc_scores(references, predictions)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"17f359d40900472b901aafa7aa973d80","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1443.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Count: 5770\n","Ref: 38-летний сергей вотинцев арестован по подозрению в серийных изнасилованиях . по данным ск , он знакомился с жертвами в соцсетях , после чего приглашал их в гостиницу « измайлово » — и там насиловал и грабил . одна из пострадавших , которой удалось сбежать , рассказала , что мужчина пугал девушек и шантажировал , представляясь сотрудником полиции .\n","Hyp: в москве расследуется дело 38-летнего сергея вотинцева , которого подозревают в серии изнасилований , совершенных в гостинице « измайлово » . как сообщает столичное управление следственного комитета , в его деле сейчас два эпизода . « следственными органами главного следственного управления следственного комитета российской федерации по городу москве возбуждено уголовное дело в отношении 38-летнего мужчины , — говорится в заявлении .\n","BLEU:  0.45151834032852867\n","ROUGE:  {'rouge-1': {'f': 0.2800573877201175, 'p': 0.2975514423145434, 'r': 0.2800350436017982}, 'rouge-2': {'f': 0.12348848845761633, 'p': 0.14225508964754116, 'r': 0.11538968734060902}, 'rouge-l': {'f': 0.23943262903764773, 'p': 0.2689299684939082, 'r': 0.25140829015483257}}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4Kc0etEGfJ0p"},"source":[""],"execution_count":null,"outputs":[]}]}